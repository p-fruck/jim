<div id="meet"></div>
<audio id="audio" onended="onAudioEnded()" autoplay></audio>

<script src='https://meet.jit.si/external_api.js'></script>

<script>
    let api; // The jitsi api object
    let isFirstPlay = true;
    const audio = document.getElementById('audio'); // the audio source object
    let gainNode;

    function dummyMessageListener(event) {}
    /**
     * Populates the meet container with a jitsi meet iframe and
     * joins a given conference
     *
     * @param {string} roomName - The room to join
     * @param {string} displayName - The name of the bot
     */
    function joinConference(roomName, displayName, initialVolume) {
        const domain = 'meet.jit.si';
        const options = {
            userInfo: {
                displayName,
            },
            roomName,
            width: 700,
            height: 700,
            parentNode: document.querySelector('#meet'),
            configOverwrite: {
                startWithAudioMuted: false,
                startWithVideoMuted: true,

                startAudioOnly: true,
                // startSilent: true, // further testing required
                audioQuality: {
                    stereo: true,
                    opusMaxAverageBitrate: 510000 // Value to fit the 6000 to 510000 range.
                },
                prejoinPageEnabled: false,
            }
        };

        api = new JitsiMeetExternalAPI(domain, options);

        api.getIFrame().setAttribute('sandbox', ""); // allow-same-origin

        const iframeNav = api.getIFrame().contentWindow.navigator;

        const audioContext = new AudioContext();
        const track = audioContext.createMediaElementSource(audio);
        gainNode = audioContext.createGain();
        const destStream = audioContext.createMediaStreamDestination();

        gainNode.gain.value = initialVolume;

        track
            .connect(gainNode)
            .connect(destStream);

        audio.onplay = function() {
            iframeNav.mediaDevices.getUserMedia = async function() {
                await audioContext.resume()
                return destStream.stream;
            };
        };
    }

    /**
     * Function to get current gain value in percent
     *
     * @returns {number} - The gain in percent
     */
    function getGain() {
        return Math.floor(gainNode.gain.value * 100);
    }

    /**
     * Set the gain value
     *
     * @param {number} gain - The gain value in percent
     */
    function setGain(gain) {
        gain = (gain / 100).toPrecision(3);
        if (gain > 1) gainNode.gain.value = 1;
        else if (gain < 0) gainNode.gain.value = 0;
        else gainNode.gain.value = gain;
    }

    /**
     * Take an url to an audio file and use it as microphone input
     *
     * @param {string} url - The url to play back
     */
    async function playAudio(url) {
        console.warn('Trying to play back', url);
        // if (audioContext.state === 'running') {
        //     await audioContext.suspend();
        // }
        await audio.pause();
        audio.setAttribute("src", url);
        await audio.play();

        if (isFirstPlay) {
            // current audio device has to be refreshed to recognize stream
            const devices = await api.getAvailableDevices();
            if (devices.audioInput.length) {
                const [{ label, deviceId }] = devices.audioInput;
                api.setAudioInputDevice(label, deviceId);
            }
            isFirstPlay = false;
        }
    }
</script>
